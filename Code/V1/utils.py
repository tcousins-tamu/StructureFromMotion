import cv2
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import open3d as o3d


def GetImageMatches(img1, img2):
    # This function utilizes the SURF algorithm in order to
    # Generate features and descriptors for the two images.
    surfer = cv2.ORB_create(nfeatures=2000)
    # surfer = cv2.xfeatures2d.SURF_create()
    kp1, desc1 = surfer.detectAndCompute(img1, None)
    kp2, desc2 = surfer.detectAndCompute(img2, None)

    # Brute force feature matching
    matcher = cv2.BFMatcher(crossCheck=True)
    matches = matcher.match(desc1, desc2)

    return kp1, desc1, kp2, desc2, matches


def GetAlignedMatches(kp1, kp2, matches):
    # Using the matches and keypoints generated by the SURF algorithm,
    # This will return the matched keypoints, lined up

    # Sorting in case matches are not sorted
    matches = sorted(matches, key=lambda x: x.distance)

    # Retrieving corresponding indices fo keypoints (in both images)
    im1idx = np.array([m.queryIdx for m in matches])
    im2idx = np.array([m.trainIdx for m in matches])

    # Filtering out the keypoints that did not have a match
    kp1_ = (np.array(kp1))[im1idx]
    kp2_ = (np.array(kp2))[im2idx]

    # retrieve the image coordinates of the matched keypoints
    im1pts = np.array([kp.pt for kp in kp1_])
    im2pts = np.array([kp.pt for kp in kp2_])

    return im1pts, im2pts, im1idx, im2idx

# Helper Function for drawing epilines


def drawlines(img1, img2, lines, pts1, pts2, drawOnly=None, linesize=3, circlesize=10):
    ''' img1 - image on which we draw the epilines for the points in img2
        lines - corresponding epilines '''
    r, c = img1.shape[:-1]

    img1_, img2_ = np.copy(img1), np.copy(img2)

    drawOnly = lines.shape[0] if (drawOnly is None) else drawOnly

    i = 0
    for r, pt1, pt2 in zip(lines, pts1, pts2):
        color = tuple(np.random.randint(0, 255, 3).tolist())
        x0, y0 = map(int, [0, -r[2]/r[1]])
        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])

        img1_ = cv2.line(img1_, (x0, y0), (x1, y1), color, linesize)
        img1_ = cv2.circle(img1_, tuple(pt1.astype(int)),
                           circlesize, color, -1)
        img2_ = cv2.circle(img2_, tuple(pt2.astype(int)),
                           circlesize, color, -1)

        i += 1

        if i > drawOnly:
            break

    return img1_, img2_


def pts2ply(pts, filename='out.ply'):
    # # outputs the pointcloud in a meshlab style format for viewing later
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(pts)
    o3d.io.write_point_cloud(filename, pcd)
    return 1


def DrawCorrespondences(img, ptsTrue, ptsReproj, ax, drawOnly=50):
    # Used for visualizing the reprojection error
    ax.imshow(img)

    if drawOnly > ptsTrue.shape[0]:
        drawOnly = ptsTrue.shape[0]
    randidx = np.random.choice(
        ptsTrue.shape[0], size=(drawOnly,), replace=False)
    ptsTrue_, ptsReproj_ = ptsTrue[randidx], ptsReproj[randidx]

    colors = colors = np.random.rand(drawOnly, 3)

    ax.scatter(ptsTrue_[:, 0], ptsTrue_[:, 1], marker='x', c=colors)
    ax.scatter(ptsReproj_[:, 0], ptsReproj_[:, 1], marker='.', c=colors)


def Find2D3DMatches(desc1, img1idx, desc2, img2idx, desc3, kp3, mask, pts3d):
    # Picking only those descriptors for which 3D point is available
    desc1_3D = desc1[img1idx][mask]
    desc2_3D = desc2[img2idx][mask]

    matcher = cv2.BFMatcher(crossCheck=True)
    matches = matcher.match(
        desc3, np.concatenate((desc1_3D, desc2_3D), axis=0))

    # Filtering out matched 2D keypoints from new view
    img3idx = np.array([m.queryIdx for m in matches])
    kp3_ = (np.array(kp3))[img3idx]
    img3pts = np.array([kp.pt for kp in kp3_])

    # Filtering out matched 3D already triangulated points
    pts3didx = np.array([m.trainIdx for m in matches])
    pts3didx[pts3didx >= pts3d.shape[0]] = pts3didx[pts3didx >=
                                                    pts3d.shape[0]] - pts3d.shape[0]
    pts3d_ = pts3d[pts3didx]

    return img3pts, pts3d_


# Estimating pose of a calibrated camera using Perspective n point
# taken from the upenn sfm cache
def LinearPnP(X, x, K):
    xh = np.hstack((x, np.ones((x.shape[0], 1))))
    Xh = np.hstack((X, np.ones((X.shape[0], 1))))
    xc = np.linalg.inv(K).dot(xh.T).T

    A = np.zeros((X.shape[0]*3, 12))

    for i in range(X.shape[0]):
        A[i*3, :] = np.concatenate((np.zeros((4,)), -
                                   Xh[i, :], xc[i, 1]*Xh[i, :]))
        A[i*3+1, :] = np.concatenate((Xh[i, :],
                                     np.zeros((4,)), -xc[i, 0]*Xh[i, :]))
        A[i*3+2, :] = np.concatenate((-xc[i, 1]*Xh[i, :],
                                     xc[i, 0]*Xh[i, :], np.zeros((4,))))

    u, s, v = np.linalg.svd(A)
    P = v[-1, :].reshape((4, 3), order='F').T
    R, t = P[:, :3], P[:, -1]

    u, s, v = np.linalg.svd(R)
    R = u.dot(v)
    t = t/s[0]

    if np.linalg.det(u.dot(v)) < 0:
        R = R*-1
        t = t*-1

    C = -R.T.dot(t)

    return R, t

# Camera Plotting Function


def PlotCamera(R, t, ax, scale=.5, depth=.5, faceColor='grey'):
    C = -t  # camera center (in world coordinate system)

    # Generating camera coordinate axes
    axes = np.zeros((3, 6))
    axes[0, 1], axes[1, 3], axes[2, 5] = 1, 1, 1

    # Transforming to world coordinate system
    axes = R.T.dot(axes)+C[:, np.newaxis]

    # Plotting axes
    ax.plot3D(xs=axes[0, :2], ys=axes[1, :2], zs=axes[2, :2], c='r')
    ax.plot3D(xs=axes[0, 2:4], ys=axes[1, 2:4], zs=axes[2, 2:4], c='g')
    ax.plot3D(xs=axes[0, 4:], ys=axes[1, 4:], zs=axes[2, 4:], c='b')

    # generating 5 corners of camera polygon
    pt1 = np.array([[0, 0, 0]]).T  # camera centre
    pt2 = np.array([[scale, -scale, depth]]).T  # upper right
    pt3 = np.array([[scale, scale, depth]]).T  # lower right
    pt4 = np.array([[-scale, -scale, depth]]).T  # upper left
    pt5 = np.array([[-scale, scale, depth]]).T  # lower left
    pts = np.concatenate((pt1, pt2, pt3, pt4, pt5), axis=-1)

    # Transforming to world-coordinate system
    pts = R.T.dot(pts)+C[:, np.newaxis]
    ax.scatter3D(xs=pts[0, :], ys=pts[1, :], zs=pts[2, :], c='k')

    # Generating a list of vertices to be connected in polygon
    verts = [[pts[:, 0], pts[:, 1], pts[:, 2]], [pts[:, 0], pts[:, 2], pts[:, -1]],
             [pts[:, 0], pts[:, -1], pts[:, -2]], [pts[:, 0], pts[:, -2], pts[:, 1]]]

    # Generating a polygon now..
    ax.add_collection3d(Poly3DCollection(verts, facecolors=faceColor,
                                         linewidths=1, edgecolors='k', alpha=.25))
